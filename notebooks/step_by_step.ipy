# %%
from itertools import chain
import numpy as np
import pandas as pd

import plotly.express as px
import plotly.graph_objects as go
from bayesmark.sklearn_funcs import SklearnModel

from brown_box.cost_functions import ucb_real, poi_real, ei_real
from brown_box.optimizers import MarkovGaussianProcessReal

from numpy.random import RandomState

BATCH_SIZE = 8
# %%
%%javascript
//hack to fix export
require.config({
  paths: {
    d3: 'https://cdnjs.cloudflare.com/ajax/libs/d3/5.9.2/d3',
    jquery: 'https://code.jquery.com/jquery-3.4.1.min',
    plotly: 'https://cdn.plot.ly/plotly-latest.min'
  },

  shim: {
    plotly: {
      deps: ['d3', 'jquery'],
      exports: 'plotly'
    }
  }
});
# %% [markdown]
# Define plot function to show current shape of GP approximation
# %%
def plot_GP(optimizer, X, y, hyper_points=None, n_pixels=500):
    _n_estimators = np.linspace(optimizer.tr._lb[0], optimizer.tr._ub[0], n_pixels)
    _learning_rates = np.logspace(optimizer.tr._lb[1], optimizer.tr._ub[1], n_pixels)

    gp = optimizer._gp()
    gp.fit(X, y)

    _X = np.column_stack([np.tile(_n_estimators, n_pixels), np.repeat(_learning_rates, n_pixels)])
    _y = gp.predict(_X)

    hyper_df = pd.DataFrame(hyper_points)

    fig = px.scatter(
        hyper_df, 
        x='n_estimators', 
        y='learning_rate',
        text=hyper_df.index+1,
        size=[0]*len(hyper_df),
        hover_name=[f"Id: {idx}" for idx in hyper_df.index],
        log_y=True,
        range_x=(optimizer.tr._lb[0], optimizer.tr._ub[0]),
        range_y=(0.0001, 10),
        width=n_pixels,
        height=n_pixels,
    )
    fig.add_trace(
        go.Heatmap(
            x=_n_estimators,
            y=_learning_rates,
            z=_y.reshape(n_pixels, n_pixels),
            opacity=0.75,
            colorscale='RdBu',
        )
    )
    fig.update_layout(
        legend_orientation='h',
        title='Model values',
        plot_bgcolor="rgba(0,0,0,0)",
        paper_bgcolor="rgba(0,0,0,0)",
    )
    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='black')
    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='black')
    return fig

def plot_cost(cost, optimizer, X, y, hyper_points=None, n_pixels=500):
    _n_estimators = np.linspace(optimizer.tr._lb[0], optimizer.tr._ub[0], n_pixels)
    _learning_rates = np.logspace(optimizer.tr._lb[1], optimizer.tr._ub[1], n_pixels)
    gp = optimizer._gp()
    gp.fit(X, y)

    _cost = cost(
                gp,
                optimizer.tr,
                max_y=max(y),
                min_y=min(y),
                xi=0.1,
                kappa=2.6,
            )
    _X = np.column_stack([np.tile(_n_estimators, n_pixels), np.repeat(_learning_rates, n_pixels)])
    _y = _cost(_X)

    hyper_df = pd.DataFrame(hyper_points)

    fig = px.scatter(
        hyper_df, 
        x='n_estimators', 
        y='learning_rate',
        text=hyper_df.index+1,
        size=[0]*len(hyper_df),
        hover_name=[f"Id: {idx}" for idx in hyper_df.index],
        log_y=True,
        range_x=(optimizer.tr._lb[0], optimizer.tr._ub[0]),
        range_y=(0.0001, 10),
        width=n_pixels,
        height=n_pixels,
    )
    fig.add_trace(
        go.Heatmap(
            x=_n_estimators,
            y=_learning_rates,
            z=_y.reshape(n_pixels, n_pixels),
            opacity=0.75,
            colorscale='RdBu',
        )
    )
    fig.update_layout(
        legend_orientation='h',
        title=f"Cost function {cost.__name__}",
        plot_bgcolor="rgba(0,0,0,0)",
        paper_bgcolor="rgba(0,0,0,0)",
    )
    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='black')
    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='black')
    return fig
# %%[markdown]
# ## Define problem
# We have selected `ada` optimizer on dataset `wine` with `nll` metric.
# Optimizer was selected with respect to number of hyperparameters (althought it is slower to evaluate)
# %%
rnd = RandomState(seed=42)
np.random.seed(42)
problem = SklearnModel(
    "ada", "wine", "acc", data_root="/mnt/workspace/output/run_fixed"
)
optimizer = MarkovGaussianProcessReal(
    problem.api_config, random=rnd, cost=ucb_real
)
# %%[markdown]
# ## Step 1 (initialize without inspection)
INIT_STEPS=1
# %%
visible_to_opt = []
generalization = []
suggestions = []
for _ in range(INIT_STEPS):
    _suggestions = optimizer.suggest(BATCH_SIZE)
    responses = []
    for suggestion in _suggestions:
        responses.append(problem.evaluate(suggestion))
    responses = np.asarray(responses)
    _visible_to_opt = responses[:, 0]
    _generalization = responses[:, 1]
    optimizer.observe(suggestions, _visible_to_opt)
    visible_to_opt = np.concatenate([visible_to_opt, _visible_to_opt])
    generalization = np.concatenate([generalization, _generalization])
    suggestions += _suggestions


# %% [markdown]
# ## Plot model and costs
# %%
_known_points = {k: [dic[k] for dic in suggestions] for k in suggestions[0]}
X = optimizer.tr.to_real_space(**_known_points)
plot_GP(optimizer, X, visible_to_opt, suggestions)
# %%
plot_cost(ucb_real, optimizer, X, visible_to_opt, suggestions)
# %%
plot_cost(ei_real, optimizer, X, visible_to_opt, suggestions)
# %%
plot_cost(poi_real, optimizer, X, visible_to_opt, suggestions)
# %%
suggestions

# %%[markdown]
# ## Step 2 (with GP)
# %%
_suggestions = optimizer.suggest(BATCH_SIZE)
# %% [markdown]
# ## Suggested points
# %%
plot_cost(ucb_real, optimizer, X, visible_to_opt, _suggestions)
_suggestions
# %% [markdown]
# ## Calculate respective responses
# %%
responses = []
for suggestion in _suggestions:
    responses.append(problem.evaluate(suggestion))
responses = np.asarray(responses)
_visible_to_opt = responses[:, 0]
_generalization = responses[:, 1]
# %% [markdown]
# ## Differences between model and real values
# %%
gp = optimizer._gp()
_M = {k: [dic[k] for dic in _suggestions] for k in _suggestions[0]}
M = optimizer.tr.to_real_space(**_M)
gp.fit(X, visible_to_opt)
_model_values = gp.predict(M)
print(f"Mean absolute error: {abs(_model_values - _visible_to_opt).mean():.3f}")
print(f"Mean square error: {((_model_values - _visible_to_opt)**2).mean():.3f}")
# %% [markdown]
# ## Updated model
# %%
_known_points = {k: [dic[k] for dic in chain(suggestions, _suggestions)] for k in suggestions[0]}
X = optimizer.tr.to_real_space(**_known_points)
y = np.asarray(list(chain(visible_to_opt, _visible_to_opt)))
f=plot_GP(optimizer, X, y, chain(suggestions, _suggestions))
# %% [markdown]
# ## Updated losses
# %%
plot_cost(ucb_real, optimizer, X, y, chain(suggestions, _suggestions))
plot_cost(ei_real, optimizer, X, y, chain(suggestions, _suggestions))
f=plot_cost(poi_real, optimizer, X, y, chain(suggestions, _suggestions))

# %%

gp = optimizer._gp()
gp.fit(X, visible_to_opt)

_cost = poi_real(
            gp,
            optimizer.tr,
            max_y=max(visible_to_opt),
            min_y=min(visible_to_opt),
            xi=0.1,
            kappa=2.6,
        )
# %%
